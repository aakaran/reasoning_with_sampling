<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Reasoning Without Training: Your Base Model is Smarter Than You Think - achieving RL-level reasoning performance through inference-time MCMC sampling.">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Reasoning Without Training: Your Base Model is Smarter Than You Think</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  
  <style>
    .publication-title {
      font-family: 'Google Sans', sans-serif;
    }
    .publication-authors {
      font-family: 'Google Sans', sans-serif;
    }
    .dnerf {
      font-weight: bold;
      color: #3273dc;
    }
    
    h1.title,
    h2.title,
    h3.title,
    h2.subtitle,
    h3.subtitle {
      text-align: center;
    }

    figcaption {
      text-align: center;
    }


  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Reasoning Without Training: Your Base Model is Smarter Than You Think</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="#">Aayush Karan</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="#">Yilun Du</a><sup>1</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Harvard University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
<div class="is-size-5 mt-3">
                <span class="has-text-weight-bold">Summary:</span> With our sampler, base models can achieve single-shot reasoning performance on par with RL without any additional training or access to a verifier while avoiding a collapse in generation diversity and multi-shot (pass@k) performance.
              </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="placeholder-teaser.png" alt="Teaser figure showing performance comparison" style="width: 100%;">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Frontier reasoning models have exhibited incredible capabilities across a wide array of disciplines, 
            driven by posttraining large language models (LLMs) with reinforcement learning (RL). However, 
            despite the widespread success of this paradigm, much of the literature has been devoted to 
            disentangling truly novel behaviors that emerge during RL but are not present in the base models.
          </p>
          <p>
            In our work, we approach this question from a different angle, instead asking whether comparable 
            reasoning capabilities can be elicited from base models at inference time, <strong>without any 
            additional training</strong>. Inspired by Markov chain Monte Carlo (MCMC) techniques for sampling 
            from sharpened distributions, we propose a simple iterative sampling algorithm leveraging the base 
            models' own likelihoods.
          </p>
          <p>
            Over different base models, we show that our algorithm offers substantial boosts in reasoning that 
            nearly match and even outperform those from RL on a wide variety of single-shot tasks, including 
            MATH500, HumanEval, and GPQA. Moreover, our sampler avoids the collapse in diversity over multiple 
            samples that is characteristic of RL posttraining. Crucially, our method does not require training, curated 
            datasets, or a verifier, suggesting broad applicability beyond easily verifiable domains.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">

        <h3 class="title is-4">Power Distributions for Reasoning</h3>
        <div class="content has-text-justified">
          <p>
            RL has emerged as the central paradigm to enhance reasoning capabilities in frontier models,
            leading to substantial boosts in performance across domains such as mathematics and coding. At the same time,
            there is evidence to suggest that the reasoning chains that emerge after RL-posttraining are well within base model
            capabilities. For example, we can plot the log likelihoods and confidences (i.e., negative average per-token entropies)
            of outputs <strong>with respect to the base model distribution</strong> and observe that RL outputs tightly concentrate around 
            high likelihood and high confidence regions of the base model. This points towards an effective <strong>distribution sharpening</strong>,
            where RL shifts probability mass from low-likelihood sequences to high-likelihood ones. 
          </p>
          <div style="text-align:center; margin: 24px 0;">
            <img src="combined_hists.png" alt="Combined Histograms" width="90%">
          </div>
          <p>
            Motivated by this observation, we introduce sampling from the <strong>power distribution</strong> \( p^{\alpha} \), 
            which naturally sharpens the base model distribution \(p\) by upweighting high-likelihood sequences via exponentiation. 
            Crucially, unlike simple low-temperature sampling, power distributions account for future completion 
            likelihoods, favoring tokens with fewer but higher likelihood future paths. This is especially valuable for reasoning tasks, 
            as it encourages avoiding "critical windows" or "pivotal tokens" that trap outputs in low-likelihood futures.
          </p>
        </div>

        <h3 class="title is-4">Autoregressive MCMC Sampling</h3>
        <div class="content has-text-justified">
          <p>
            Directly sampling from \( p^{\alpha} \) is intractable, as it requires normalizing over a sequence space that 
            is exponential in length. To get around this, we employ a Metropolis-Hastings (MCMC) method to approximately 
            sample from the unnormalized distribution \( p^{\alpha} \). Metropolis-Hastings iteratively updates a sample
            generation \(\mathbf{x}\) by proposing a new candidate \(\mathbf{x'}\) and accepting the change with some probability
            \(A(\mathbf{x}, \mathbf{x'})\) which depends on the \( p^{\alpha} \) weights. We illustrate the process below:
          </p>
          <!-- Embed block START -->
          <figure style="margin: 24px 0; text-align: center;">
            <div style="
                max-width: 900px;
                margin: 0 auto;
                border: 1px solid #e5e7eb;
                border-radius: 10px;
                overflow: hidden;
                aspect-ratio: 16 / 9;">
              <!-- Use iframe for an external HTML file -->
              <iframe
                src="mh.html"
                title="MCMC Illustration"
                style="width: 100%; height: 100%; border: 0;"
                loading="lazy"
                referrerpolicy="no-referrer"
                allowfullscreen>
              </iframe>
            </div>
            <figcaption style="color:#6b7280; font-size: 0.9rem; margin-top: 8px;">
              Illustration of Metropolis-Hastings updates.
            </figcaption>
            <noscript>
              Your browser has JavaScript disabled. You can <a href="mh_animation.html">open the interactive version</a>.
            </noscript>
          </figure>
          <!-- Embed block END -->
          <p>
            In general, Metropolis-Hastings can require exponentially many iterative updates before converging to sampling from 
            \( p^{\alpha} \) with such a large sequence space. To avoid this curse of dimensionality, we build the output block-by-block,
            using Metropolis-Hastings to sample from \( p^{\alpha} \) for progressively longer sequences. This amounts to probabilistic iterative 
            resampling informed by base model likelihoods. 
          </p>
          <!-- Embed block START -->
          <figure style="margin: 24px 0; text-align: center;">
            <div style="
                max-width: 900px;
                margin: 0 auto;
                border: 1px solid #e5e7eb;
                border-radius: 10px;
                overflow: hidden;
                aspect-ratio: 48 / 9;">
              <!-- Use iframe for an external HTML file -->
              <iframe
                src="block_mcmc.html"
                title="MCMC Illustration"
                style="width: 100%; height: 100%; border: 0;"
                loading="lazy"
                referrerpolicy="no-referrer"
                allowfullscreen>
              </iframe>
            </div>
            <figcaption style="color:#6b7280; font-size: 0.9rem; margin-top: 8px;">
              Illustration of block-wise autoregressive MCMC sampling.
            </figcaption>
            <noscript>
              Your browser has JavaScript disabled. You can <a href="mh_animation.html">open the interactive version</a>.
            </noscript>
          </figure>
          <!-- Embed block END -->
          <p>
            Our algorithm, called <em>power sampling</em>, is thus <strong>training-free</strong>, <strong>dataset-free</strong>, and 
            <strong>verifier-free</strong>, avoiding the hyperparameter tuning, dataset curation, and 
            reward signal requirements of RL posttraining.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="columns is-centered">
  <div class="container is-max-desktop">    
    <div class="content has-text-justified">
    </div>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h3 class="title is-4">Single-shot Reasoning</h3>
        <div class="content">
          <p>
            Remarkably, the outputs generated by power sampling from the base model are <strong>on par with, if not better than</strong>, RL-posttraining on a variety
            of reasoning tasks and base models. We look at MATH500, HumanEval, and GPQA Diamond as benchmarks of difficult mathematics, coding, and science questions.
            We compare against a GRPO baseline (using the MATH training dataset), the poster child for RL-posttraining, as well as the original base model itself. 
            We also include the AlpacaEval 2.0 benchmark, a non-verifiable, general helpfulness benchmark, to demonstrate our applicability beyond the verifiable regime.
          </p>
          <div style="text-align:center; margin: 24px 0;">
            <img src="teaser.png" alt="Single-Shot Reasoning" width="100%">
            <figcaption style="color:#6b7280; font-size: 0.9rem; margin-top: 8px;">
              Single-shot reasoning performance of power sampling and GRPO relative to the base model for Qwen2.5-Math-7B.
            </figcaption>

          </div>
          <p>
            In-domain (MATH500), power sampling surprisingly is close to the performance of GRPO without ever changing the base model's weights.
            Out-of-domain, power sampling can actually <strong>outperform</strong> GRPO, as demonstrated on HumanEval and AlpacaEval 2.0. 
          </p>
          </ul>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h3 class="title is-4">Diversity and Pass@\(k\) Performance</h3>
        <div class="content has-text-justified">
          <p>
            RL-posttraining methods like GRPO are known to exhibit <strong>diversity collpase</strong> as measured by a <strong>deteriorated pass@\(k\)</strong> 
            performance (where a problem is solved if at least one of k samples is correct). While single-shot reasoning demonstrates considerable boosts, <em>multi-shot</em> reasoning
            deteriorates: in fact, the base model pass@\(k\) performance typically exceeds that of GRPO for large enough \(k\).
          </p>
          <div style="text-align:center; margin: 24px 0;">
            <img src="passatk.png" alt="Multi-Shot Reasoning" width="100%">
            <figcaption style="color:#6b7280; font-size: 0.9rem; margin-top: 8px;">
              Pass@\(k\) performance of power sampling and GRPO relative to the base model for Qwen2.5-Math-7B.
            </figcaption>
          </div>
          <p>
            Unlike GRPO, power sampling maintains generation diversity and pass@\(k\) performance. Our algorithm universally <strong>outperforms</strong>
            both GRPO as well as the base model on pass@\(k\) for \(k>1\), demonstrating that we are able to achieve the best of both worlds: both strong
            single-shot as well as multi-shot reasoning without compromising generation diversity.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Implications</h2>

        <div class="content has-text-justified">
          <p>
            Our work demonstrates that <strong>base models are significantly more capable at reasoning than 
            standard sampling methods reveal</strong>. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{karan2025reasoning,
  author    = {Karan, Aayush and Du, Yilun},
  title     = {Reasoning Without Training: Your Base Model is Smarter Than You Think},
  journal   = {NeurIPS},
  year      = {2025},
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="#">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="#" class="external-link">
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website template is borrowed from <a href="https://nerfies.github.io/">Nerfies</a>, 
            licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
